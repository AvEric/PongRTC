{"ts":1354048721016,"silentsave":true,"restoring":false,"patch":[[]],"length":0}
{"contributors":[],"silentsave":true,"ts":1354048728466,"patch":[[{"diffs":[[1,"/**\r\n * Calculates an estimate of the position of the head of the user in relation to screen or camera\r\n *   based on input from facetrackrObject\r\n *\r\n * Usage:\r\n *    var hp = new headtrackr.headposition.Tracker(facetrackrObject, 640, 480);\r\n *\tvar currentPosition = hp.track(facetrackrObject);\r\n *\r\n * @author auduno / github.com/auduno\r\n */\r\n\r\nheadtrackr.headposition = {};\r\n\r\n/**\r\n *\r\n * Parameters to Tracker() are:\r\n *\tfacetrackrObject : a generic object with attributes x, y, width, height, angle\r\n *\t\twhich describe the position of center of detected face\r\n *\tcamwidth : width of canvas where the face was detected\r\n *\tcamheight : height of canvas where the face was detected\r\n *\r\n * Optional parameters can be passed along like this:\r\n *\t headtrackr.headposition.Tracker(facetrackrObject, 640, 480, {fov : 60})\r\n *\r\n * Optional parameters:\r\n *\t fov {number} : horizontal field of view of camera (default is to detect via distance to screen, any fov overrides distance_to_screen)\r\n *\t distance_to_screen {number} : initial distance from face to camera, in cms (default is 60 cm)\r\n *\t edgecorrection {boolean} : whether to use heuristic for position of head when detection is on the edge of the screen (default is true)\r\n *\t distance_from_camera_to_screen : distance from camera to center of screen (default is 11.5 cm, typical for laptops)\r\n *\r\n * Returns a generic object with attributes x, y, z which is estimated headposition in cm in relation to center of screen\r\n *\r\n * @constructor\r\n */\r\nheadtrackr.headposition.Tracker = function(facetrackrObj, camwidth, camheight, params) {\r\n\t\r\n\t// some assumptions that are used when calculating distances and estimating horizontal fov\r\n\t//\t head width = 16 cm\r\n\t//\t head height = 19 cm\r\n\t//\t when initialized, user is approximately 60 cm from camera\r\n\t\r\n\tif (!params) params = {};\r\n\t\r\n\tif (params.edgecorrection === undefined) {\r\n\t\tvar edgecorrection = true;\r\n\t} else {\r\n\t\tvar edgecorrection = params.edgecorrection;\r\n\t}\r\n\t\r\n\tthis.camheight_cam = camheight;\r\n\tthis.camwidth_cam = camwidth;\r\n\t\r\n\tvar head_width_cm = 16;\r\n\tvar head_height_cm = 19;\r\n\t\r\n\t// angle between side of face and diagonal across\r\n\tvar head_small_angle = Math.atan(head_width_cm/head_height_cm);\r\n\t\r\n\tvar head_diag_cm = Math.sqrt((head_width_cm*head_width_cm)+(head_height_cm*head_height_cm)); // diagonal of face in real space\r\n\t\r\n\tvar sin_hsa = Math.sin(head_small_angle); //precalculated sine\r\n\tvar cos_hsa = Math.cos(head_small_angle); //precalculated cosine\r\n\tvar tan_hsa = Math.tan(head_small_angle); //precalculated tan\r\n\t\r\n\t// estimate horizontal field of view of camera\r\n\tvar init_width_cam = facetrackrObj.width;\r\n\tvar init_height_cam = facetrackrObj.height;\r\n\tvar head_diag_cam = Math.sqrt((init_width_cam*init_width_cam)+(init_height_cam*init_height_cam));\r\n\tif (params.fov === undefined) {\r\n\t\t// we use the diagonal of the faceobject to estimate field of view of the camera\r\n\t\t// we use the diagonal since this is less sensitive to errors in width or height\r\n\t\tvar head_width_cam = sin_hsa * head_diag_cam;\r\n\t\tvar camwidth_at_default_face_cm = (this.camwidth_cam/head_width_cam) * head_width_cm;\r\n\t\t// we assume user is sitting around 60 cm from camera (normal distance on a laptop)\r\n\t\tif (params.distance_to_screen === undefined) {\r\n\t\t\tvar distance_to_screen = 60;\r\n\t\t} else {\r\n\t\t\tvar distance_to_screen = params.distance_to_screen;\r\n\t\t}\r\n\t\t// calculate estimate of field of view\r\n\t\tvar fov_width = Math.atan((camwidth_at_default_face_cm/2)/distance_to_screen) * 2;\r\n\t} else {\r\n\t\tvar fov_width = params.fov * Math.PI/180;\r\n\t}\r\n\t\r\n\t// precalculate ratio between camwidth and distance\r\n\tvar tan_fov_width = 2 * Math.tan(fov_width/2);\r\n\t\r\n\tvar x, y, z; // holds current position of head (in cms from center of screen)\r\n\t\r\n\tthis.track = function(facetrackrObj) {\r\n\t\t\r\n\t\tvar w = facetrackrObj.width;\r\n\t\tvar h = facetrackrObj.height;\r\n\t\tvar fx = facetrackrObj.x; \r\n\t\tvar fy = facetrackrObj.y; \r\n\t\t\r\n\t\tif (edgecorrection) {\r\n\t\t\t// recalculate head_diag_cam, fx, fy\r\n\t\t\t\r\n\t\t\tvar margin = 11;\r\n\t\t\t\r\n\t\t\tvar leftDistance = fx-(w/2);\r\n\t\t\tvar rightDistance = this.camwidth_cam-(fx+(w/2));\r\n\t\t\tvar topDistance = fy-(h/2);\r\n\t\t\tvar bottomDistance = this.camheight_cam-(fy+(h/2));\r\n\t\t\t\r\n\t\t\tvar onVerticalEdge = (leftDistance < margin || rightDistance < margin);\r\n\t\t\tvar onHorizontalEdge = (topDistance < margin || bottomDistance < margin);\r\n\t\t\t\r\n\t\t\tif (onHorizontalEdge) {\r\n\t\t\t\tif (onVerticalEdge) {\r\n\t\t\t\t\t// we are in a corner, use previous diagonal as estimate, i.e. don't change head_diag_cam\r\n\t\t\t\t\tvar onLeftEdge = (leftDistance < margin);\r\n\t\t\t\t\tvar onTopEdge = (topDistance < margin);\r\n\t\t\t\t\t\r\n\t\t\t\t\tif (onLeftEdge) {\r\n\t\t\t\t\t\tfx = w-(head_diag_cam * sin_hsa/2);\r\n\t\t\t\t\t} else {\r\n\t\t\t\t\t\tfx = fx-(w/2)+(head_diag_cam * sin_hsa/2);\r\n\t\t\t\t\t}\r\n\t\t\t\t\t\r\n\t\t\t\t\tif (onTopEdge) {\r\n\t\t\t\t\t\tfy = h-(head_diag_cam * cos_hsa/2);\r\n\t\t\t\t\t} else {\r\n\t\t\t\t\t\tfy = fy-(h/2)+(head_diag_cam*cos_hsa/2);\r\n\t\t\t\t\t}\r\n\t\t\t\t\t\r\n\t\t\t\t} else {\r\n\t\t\t\t\t// we are on top or bottom edge of camera, use width instead of diagonal and correct y-position\r\n\t\t\t\t\t// fix fy\r\n\t\t\t\t\tif (topDistance < margin) {\r\n            var originalWeight = topDistance/margin;\r\n            var estimateWeight = (margin-topDistance)/margin;\r\n\t\t\t\t\t\tfy = h-(originalWeight*(h/2) + estimateWeight*((w/tan_hsa)/2));\r\n            head_diag_cam = estimateWeight*(w/sin_hsa) + originalWeight*(Math.sqrt((w*w)+(h*h)));\r\n\t\t\t\t\t} else {\r\n            var originalWeight = bottomDistance/margin;\r\n            var estimateWeight = (margin-bottomDistance)/margin;\r\n\t\t\t\t\t\tfy = fy-(h/2)+(originalWeight*(h/2) + estimateWeight*((w/tan_hsa)/2));\r\n            head_diag_cam = estimateWeight*(w/sin_hsa) + originalWeight*(Math.sqrt((w*w)+(h*h)));\r\n\t\t\t\t\t}\r\n\t\t\t\t}\r\n\t\t\t} else if (onVerticalEdge) {\r\n\t\t\t\t// we are on side edges of camera, use height and correct x-position\r\n\t\t\t\tif (leftDistance < margin) {\r\n          var originalWeight = leftDistance/margin;\r\n          var estimateWeight = (margin-leftDistance)/margin;\r\n          head_diag_cam = estimateWeight*(h/cos_hsa) + originalWeight*(Math.sqrt((w*w)+(h*h)));\r\n\t\t\t\t\tfx = w-(originalWeight*(w/2)+(estimateWeight)*(h*tan_hsa/2));\r\n\t\t\t\t} else {\r\n          var originalWeight = rightDistance/margin;\r\n          var estimateWeight = (margin-rightDistance)/margin;\r\n          head_diag_cam = estimateWeight*(h/cos_hsa) + originalWeight*(Math.sqrt((w*w)+(h*h)));\r\n\t\t\t\t\tfx = fx-(w/2)+(originalWeight*(w/2) + estimateWeight*(h*tan_hsa/2));\r\n\t\t\t\t}\r\n\t\t\t} else {\r\n\t\t\t\thead_diag_cam = Math.sqrt((w*w)+(h*h));\r\n\t\t\t}\r\n\t\t} else {\r\n\t\t\thead_diag_cam = Math.sqrt((w*w)+(h*h));\r\n\t\t}\r\n\t\t\r\n\t\t// calculate cm-distance from screen\r\n\t\tz = (head_diag_cm*this.camwidth_cam)/(tan_fov_width*head_diag_cam);\r\n\t\t// to transform to z_3ds : z_3ds = (head_diag_3ds/head_diag_cm)*z\r\n\t\t// i.e. just use ratio\r\n\t\t\r\n\t\t// calculate cm-position relative to center of screen\r\n\t\tx = -((fx/this.camwidth_cam) - 0.5) * z * tan_fov_width;\r\n\t\ty = -((fy/this.camheight_cam) - 0.5) * z * tan_fov_width * (this.camheight_cam/this.camwidth_cam);\r\n\t\t\r\n\t\t\r\n\t\t// Transformation from position relative to camera, to position relative to center of screen\r\n\t\tif (params.distance_from_camera_to_screen === undefined) {\r\n\t\t\t// default is 11.5 cm approximately\r\n\t\t\ty = y + 11.5;\r\n\t\t} else {\r\n\t\t\ty = y + params.distance_from_camera_to_screen;\r\n\t\t}\r\n\t\t\t\t\t\r\n\t\t// send off event\r\n\t\tvar evt = document.createEvent(\"Event\");\r\n\t\tevt.initEvent(\"headtrackingEvent\", true, true);\r\n\t\tevt.x = x;\r\n\t\tevt.y = y;\r\n\t\tevt.z = z;\r\n\t\tdocument.dispatchEvent(evt);\r\n\t\t\r\n\t\treturn new headtrackr.headposition.TrackObj(x,y,z);\r\n\t}\r\n\t\r\n\t\r\n\tthis.getTrackerObj = function() {\r\n\t\treturn new headtrackr.headposition.TrackObj(x,y,z);\r\n\t}\r\n\t\r\n\tthis.getFOV = function() {\r\n\t\treturn fov_width * 180/Math.PI;\r\n\t}\r\n}; \r\n\r\n/**\r\n * @constructor\r\n */\r\nheadtrackr.headposition.TrackObj = function(x,y,z) {\r\n\tthis.x = x;\r\n\tthis.y = y;\r\n\tthis.z = z;\r\n\t\r\n\tthis.clone = function() {\r\n\t\tvar c = new headtrackr.headposition.TrackObj();\r\n\t\tc.x = this.x;\r\n\t\tc.y = this.y;\r\n\t\tc.z = this.z;\r\n\t\treturn c;\r\n\t}\r\n};"]],"start1":0,"start2":0,"length1":0,"length2":7987}]],"length":7987,"saved":false}
