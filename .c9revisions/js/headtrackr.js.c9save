{"ts":1354044510171,"silentsave":true,"restoring":false,"patch":[[]],"length":0}
{"contributors":[],"silentsave":true,"ts":1354044511769,"patch":[[{"diffs":[[1,"/**\r\n * Wrapper for headtrackr library\r\n *\r\n * Usage:\r\n *    var htracker = new headtrackr.Tracker(); \r\n *\thtracker.init(videoInput, canvasInput); \r\n *\thtracker.start(); \r\n * \r\n * Optional parameters can be passed to Tracker like this:\r\n *\t new headtrackr.Tracker({ ui : false, altVideo : \"somevideo.ogv\" });\r\n *\r\n * Optional parameters:\r\n *\tui {boolean} : whether to create messageoverlay with messages like \"found face\" (default is true)\r\n *\taltVideo {object} : urls to any alternative videos, if camera is not found or not supported\r\n *      the format is : {'ogv' : 'somevideo.ogv', 'mp4' : 'somevideo.mp4', 'webm' : 'somevideo.webm'}\r\n *\tsmoothing {boolean} : whether to use smoothing (default is true)\r\n *\tdebug {canvas} : pass along a canvas to paint output of facedetection, for debugging\r\n *\tdetectionInterval {number} : time we wait before doing a new facedetection (default is 20 ms)\r\n *\tretryDetection {boolean} : whether to start facedetection again if we lose track of face (default is true)\r\n *\tfov {number} : horizontal field of view of used camera in degrees (default is to estimate this)\r\n *\tfadeVideo {boolean} : whether to fade out video when face is detected (default is false)\r\n *\tcameraOffset {number} : distance from camera to center of screen, used to offset position of head (default is 11.5)\r\n *\tcalcAngles {boolean} : whether to calculate angles when doing facetracking (default is false)\r\n *\theadPosition {boolean} : whether to calculate headposition (default is true)\r\n *\r\n * @author auduno / github.com/auduno\r\n */\r\n\r\nvar headtrackr = {};\r\n\r\n/**\r\n * @constructor\r\n */\r\nheadtrackr.Tracker = function(params) {\r\n\t\r\n\tif (!params) params = {};\r\n\t\r\n\tif (params.smoothing === undefined) params.smoothing = true;\r\n\tif (params.retryDetection === undefined) params.retryDetection = true;\r\n\tif (params.ui === undefined) params.ui = true;\r\n\tif (params.debug === undefined) {\r\n\t\tparams.debug = false;\r\n\t} else {\r\n\t\tif (params.debug.tagName != 'CANVAS') {\r\n\t\t\tparams.debug = false;\r\n\t\t} else {\r\n\t\t\tvar debugContext = params.debug.getContext('2d');\r\n\t\t}\r\n\t}\r\n\tif (params.detectionInterval === undefined) params.detectionInterval = 20;\r\n\tif (params.fadeVideo === undefined) params.fadeVideo = false;\r\n\tif (params.cameraOffset === undefined) params.cameraOffset = 11.5;\r\n\tif (params.calcAngles === undefined) params.calcAngles = false;\r\n\tif (params.headPosition === undefined) params.headPosition = true;\r\n\t\r\n\tvar ui, smoother, facetracker, headposition, canvasContext, videoElement, detector;\r\n\tvar detectionTimer;\r\n\tvar fov = 0;\r\n\tvar initialized = true;\r\n\tvar run = false;\r\n\tvar faceFound = false;\r\n\tvar firstRun = true;\r\n\tvar videoFaded = false;\r\n\tvar headDiagonal = [];\r\n\t\r\n\tthis.status = \"\";\r\n\t\r\n  var statusEvent = document.createEvent(\"Event\");\r\n  statusEvent.initEvent(\"headtrackrStatus\", true, true);\r\n\t\r\n\tvar headtrackerStatus = function(message) {\r\n\t  statusEvent.status = message;\r\n\t\tdocument.dispatchEvent(statusEvent);\r\n\t\tthis.status = message;\r\n\t}.bind(this);\r\n\t\r\n\tvar insertAltVideo = function(video) {\r\n\t  if (params.altVideo !== undefined) {\r\n        if (supports_video()) {\r\n          if (params.altVideo.ogv && supports_ogg_theora_video()) {\r\n            video.src = params.altVideo.ogv;\r\n          } else if (params.altVideo.mp4 && supports_h264_baseline_video()) {\r\n            video.src = params.altVideo.mp4;\r\n          } else if (params.altVideo.webm && supports_webm_video()) {\r\n            video.src = params.altVideo.webm;\r\n          } else {\r\n            return false;\r\n          }\r\n          video.play();\r\n          return true;\r\n        }\r\n      } else {\r\n        return false;\r\n      }\r\n\t}\r\n\t\r\n\tthis.init = function(video, canvas) {\r\n    navigator.getUserMedia = navigator.getUserMedia || navigator.webkitGetUserMedia || navigator.mozGetUserMedia || navigator.msGetUserMedia;\r\n\t\twindow.URL = window.URL || window.webkitURL || window.msURL || window.mozURL;\r\n\t\t// check for camerasupport\r\n\t\tif (navigator.getUserMedia) {\r\n\t\t  headtrackerStatus(\"getUserMedia\");\r\n\t\t  \r\n\t\t  var videoSelector = {video : true};\r\n\t\t  if (window.navigator.appVersion.match(/Chrome\\/(.*?) /)) {\r\n\t\t    var chromeVersion = parseInt(window.navigator.appVersion.match(/Chrome\\/(\\d+)\\./)[1], 10);\r\n\t\t    if (chromeVersion < 20) {\r\n\t\t      videoSelector = \"video\";\r\n\t\t    }\r\n\t\t  };\r\n\t\t  \r\n\t\t\t// set up stream\r\n\t\t\tnavigator.getUserMedia(videoSelector, function( stream ) {\r\n\t\t\t\theadtrackerStatus(\"camera found\");\r\n\t\t\t\tvideo.src = window.URL.createObjectURL(stream);\r\n\t\t\t\tvideo.play();\r\n\t\t\t}, function() {\r\n\t\t\t\theadtrackerStatus(\"no camera\");\r\n\t\t\t\tinsertAltVideo(video);\r\n\t\t\t});\r\n\t\t} else {\r\n\t\t\theadtrackerStatus(\"no getUserMedia\");\r\n\t\t\tif (!insertAltVideo(video)) {\r\n\t\t\t  return false;\r\n            }\r\n\t\t}\r\n\t\t\r\n\t\tvideoElement = video;\r\n\t\tcanvasElement = canvas;\r\n\t\tcanvasContext = canvas.getContext(\"2d\");\r\n\t\t\r\n\t\t// resize video when it is playing\r\n\t\tvideo.addEventListener('playing', function() {\r\n\t\t\tif(video.width > video.height) {\r\n\t\t\t\tvideo.width = 320;\r\n\t\t\t} else {\r\n\t\t\t\tvideo.height = 240;\r\n\t\t\t}\r\n\t\t}, false);\r\n\t\t\r\n\t\t// create ui if needed\r\n\t\tif (params.ui) {\r\n\t\t\tui = new headtrackr.Ui();\r\n\t\t}\r\n\t\t\r\n\t\t// create smoother if enabled\r\n\t\tsmoother = new headtrackr.Smoother(0.35, params.detectionInterval+15);\r\n\t\t\r\n\t\tthis.initialized = true;\r\n\t}\r\n\t\r\n\ttrack = function() {\r\n\t\t// Copy video to canvas\r\n\t\tcanvasContext.drawImage(videoElement, 0, 0, canvasElement.width, canvasElement.height);\r\n\t\t\r\n\t\t// if facetracking hasn't started, initialize facetrackr\r\n\t\tif (facetracker === undefined) {\r\n\t\t\tfacetracker = new headtrackr.facetrackr.Tracker({debug : params.debug, calcAngles : params.calcAngles});\r\n\t\t\tfacetracker.init(canvasElement);\r\n\t\t}\r\n\t\t\r\n\t\t// track face\r\n\t\tfacetracker.track()\r\n\t\tvar faceObj = facetracker.getTrackingObject({debug : params.debug});\r\n    \r\n\t\tif (faceObj.detection == \"WB\") headtrackerStatus(\"whitebalance\");\r\n\t\tif (firstRun && faceObj.detection == \"VJ\") headtrackerStatus(\"detecting\");\r\n\t\t\r\n\t\t// check if we have a detection first\r\n\t\tif (!(faceObj.confidence == 0)) {\r\n\t\t\tif (faceObj.detection == \"VJ\") {\r\n\t\t\t  if (detectionTimer === undefined) {\r\n\t\t\t    // start timing\r\n\t\t\t    detectionTimer = (new Date).getTime();\r\n\t\t\t  }\r\n\t\t\t  if (((new Date).getTime() - detectionTimer) > 5000) {\r\n\t\t\t    headtrackerStatus(\"hints\");\r\n\t\t\t  }\r\n\t\t\t  \r\n\t\t\t\tvar x = (faceObj.x + faceObj.width/2); //midpoint\r\n\t\t\t\tvar y = (faceObj.y + faceObj.height/2); //midpoint\r\n\t\t\t\t\r\n\t\t\t\tif (params.debug) {\r\n\t\t\t\t\t// draw detected face on debuggercanvas\r\n\t\t\t\t\tdebugContext.strokeStyle = \"#0000CC\";\r\n\t\t\t\t\tdebugContext.strokeRect(faceObj.x, faceObj.y, faceObj.width, faceObj.height);\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\tif (faceObj.detection == \"CS\") {\r\n\t\t\t\tvar x = faceObj.x; //midpoint\r\n\t\t\t\tvar y = faceObj.y; //midpoint\r\n\t\t\t\t\r\n\t\t\t\tif (detectionTimer !== undefined) detectionTimer = undefined;\r\n\t\t\t\t\r\n\t\t\t\tif (params.debug) {\r\n\t\t\t\t\t// draw tracked face on debuggercanvas\r\n\t\t\t\t\tdebugContext.translate(faceObj.x, faceObj.y)\r\n\t\t\t\t\tdebugContext.rotate(faceObj.angle-(Math.PI/2));\r\n\t\t\t\t\tdebugContext.strokeStyle = \"#00CC00\";\r\n\t\t\t\t\tdebugContext.strokeRect((-(faceObj.width/2)) >> 0, (-(faceObj.height/2)) >> 0, faceObj.width, faceObj.height);\r\n\t\t\t\t\tdebugContext.rotate((Math.PI/2)-faceObj.angle);\r\n\t\t\t\t\tdebugContext.translate(-faceObj.x, -faceObj.y);\r\n\t\t\t\t}\r\n\t\t\t\t\r\n\t\t\t\t// fade out video if it's showing\r\n\t\t\t\tif (!videoFaded && params.fadeVideo) {\r\n\t\t\t\t  fadeVideo();\r\n\t\t\t\t  videoFaded = true;\r\n\t\t\t\t}\r\n\t\t\t\t\r\n\t\t\t\tthis.status = 'tracking';\r\n\t\t\t\t\r\n\t\t\t\t//check if we've lost tracking of face\r\n\t\t\t\tif (faceObj.width == 0 || faceObj.height == 0) {\r\n\t\t\t\t\tif (params.retryDetection) {\r\n\t\t\t\t\t\t// retry facedetection\r\n\t\t\t\t\t\theadtrackerStatus(\"redetecting\");\r\n\t\t\t\t\t\t\r\n\t\t\t\t\t\tfacetracker = new headtrackr.facetrackr.Tracker({whitebalancing : false, debug: params.debug, calcAngles : params.calcAngles});\r\n\t\t\t\t\t\tfacetracker.init(canvasElement);\r\n\t\t\t\t\t\tfaceFound = false;\r\n\t\t\t\t\t\theadposition = undefined;\r\n\t\t\t\t\t\t\r\n\t\t\t\t\t\t// show video again if it's not already showing\r\n            if (videoFaded) {\r\n              videoElement.style.opacity = 1;\r\n              videoFaded = false;\r\n            }\r\n\t\t\t\t\t} else {\r\n\t\t\t\t\t  headtrackerStatus(\"lost\");\r\n\t\t\t\t\t\tthis.stop();\r\n\t\t\t\t\t}\r\n\t\t\t\t} else {\r\n\t\t\t\t\tif (!faceFound) {\r\n\t\t\t\t\t  headtrackerStatus(\"found\");\r\n\t\t\t\t\t\tfaceFound = true;\r\n\t\t\t\t\t}\r\n\t\t\t\t\t\r\n\t\t\t\t\tif (params.smoothing) {\r\n\t\t\t\t\t\t// smooth values\r\n\t\t\t\t\t\tif (!smoother.initialized) {\r\n\t\t\t\t\t\t\tsmoother.init(faceObj);\r\n\t\t\t\t\t\t}\r\n\t\t\t\t\t\tfaceObj = smoother.smooth(faceObj);\r\n\t\t\t\t\t}\r\n\t\t\t\t\t\r\n\t\t\t\t\t// get headposition\r\n\t\t\t\t\tif (headposition === undefined && params.headPosition) {\r\n            // wait until headdiagonal is stable before initializing headposition\r\n            var stable = false;\r\n            \r\n            // calculate headdiagonal\r\n            var headdiag = Math.sqrt(faceObj.width*faceObj.width + faceObj.height*faceObj.height);\r\n            \r\n            //console.log(headdiag);\r\n            \r\n            if (headDiagonal.length < 6) {\r\n              headDiagonal.push(headdiag);\r\n            } else {\r\n              headDiagonal.splice(0,1);\r\n              headDiagonal.push(headdiag);\r\n              if ((Math.max.apply(null, headDiagonal) - Math.min.apply(null, headDiagonal)) < 5) {\r\n                stable = true;\r\n              }\r\n            }\r\n            \r\n            if (stable) {\r\n              if (firstRun) {\r\n                if (params.fov === undefined) {\r\n                  headposition = new headtrackr.headposition.Tracker(faceObj, canvasElement.width, canvasElement.height, {distance_from_camera_to_screen : params.cameraOffset});\r\n                } else {\r\n                  headposition = new headtrackr.headposition.Tracker(faceObj, canvasElement.width, canvasElement.height, {fov : params.fov, distance_from_camera_to_screen : params.cameraOffset});\r\n                }\r\n                fov = headposition.getFOV();\r\n                firstRun = false;\r\n              } else {\r\n                headposition = new headtrackr.headposition.Tracker(faceObj, canvasElement.width, canvasElement.height, {fov : fov, distance_from_camera_to_screen : params.cameraOffset});\r\n              }\r\n              headposition.track(faceObj);\r\n\t\t\t\t\t\t}\r\n\t\t\t\t\t} else if (params.headPosition) {\r\n            headposition.track(faceObj);\r\n          }\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t \r\n\t\tif (run) {\r\n\t\t\tdetector = window.setTimeout(track, params.detectionInterval);\r\n\t\t}\r\n\t}.bind(this);\r\n\t\r\n\tvar starter = function() {\r\n    // in some cases, the video sends events before starting to draw\r\n\t\t// so check that we have something on video before starting to track\r\n    \r\n    // Copy video to canvas\r\n    canvasContext.drawImage(videoElement, 0, 0, canvasElement.width, canvasElement.height);\r\n\t\t\r\n\t\tvar canvasContent = headtrackr.getWhitebalance(canvasElement);\r\n\t\tif (canvasContent > 0) {\r\n\t\t  run = true;\r\n      track();\r\n\t\t} else {\r\n      window.setTimeout(starter, 100);\r\n\t\t}\r\n\t}\r\n\t\r\n\tthis.start = function() {\r\n\t\t// check if initialized\r\n\t\tif (!this.initialized) return false;\r\n\t\t\r\n\t\t// check if video is playing, if not, return false\r\n\t\tif (!(videoElement.currentTime > 0 && !videoElement.paused && !videoElement.ended)) {\r\n\t\t\t\r\n\t\t\trun = true;\r\n\t\t\t//set event\r\n\t\t\tvideoElement.addEventListener('playing', starter, false);\r\n\t\t\t\r\n\t\t\treturn true;\r\n\t\t} else {\t\t  \r\n      starter();\r\n    }\r\n\t\t\r\n\t\treturn true;\r\n\t}\r\n\t\r\n\tthis.stop = function() {\r\n\t\twindow.clearTimeout(detector);\r\n\t\trun = false;\r\n\t\theadtrackerStatus(\"stopped\");\r\n\t\tfacetracker = undefined;\r\n\t\tfaceFound = false;\r\n\t\t\r\n\t\treturn true;\r\n\t}\r\n\t\r\n\tthis.getFOV = function() {\r\n\t\treturn fov;\r\n\t}\r\n\t\r\n\t// fade out videoElement\r\n\tvar fadeVideo = function() {\r\n\t  if (videoElement.style.opacity == \"\") {\r\n\t    videoElement.style.opacity = 0.98;\r\n\t    window.setTimeout(fadeVideo, 50);\r\n\t  } else if (videoElement.style.opacity > 0.30) {\r\n\t    videoElement.style.opacity -= 0.02;\r\n\t    window.setTimeout(fadeVideo, 50);\r\n\t  } else {\r\n\t    videoElement.style.opacity = 0.3;\r\n\t  }\r\n\t}\r\n};\r\n\r\n// bind shim\r\n// from https://developer.mozilla.org/en/JavaScript/Reference/Global_Objects/Function/bind\r\n\r\nif (!Function.prototype.bind) {\t \r\n\tFunction.prototype.bind = function (oThis) {\t\r\n\t\tif (typeof this !== \"function\") {\t \r\n\t\t\t// closest thing possible to the ECMAScript 5 internal IsCallable function\t\r\n\t\t\tthrow new TypeError(\"Function.prototype.bind - what is trying to be bound is not callable\");\t\r\n\t\t}\t \r\n\t\r\n\t\tvar aArgs = Array.prototype.slice.call(arguments, 1),\t\t\r\n\t\t\t\tfToBind = this,\t\t\r\n\t\t\t\tfNOP = function () {},\t\r\n\t\t\t\tfBound = function () {\t\r\n\t\t\t\t\treturn fToBind.apply(this instanceof fNOP\t \r\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t ? this\t \r\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t : oThis || window,\t \r\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t aArgs.concat(Array.prototype.slice.call(arguments)));\t\r\n\t\t\t\t};\t\r\n\t\r\n\t\tfNOP.prototype = this.prototype;\t\r\n\t\tfBound.prototype = new fNOP();\t\r\n\t\r\n\t\treturn fBound;\t\r\n\t};\t\r\n}\t \r\n\r\n// video support utility functions\r\n\r\nfunction supports_video() {\r\n  return !!document.createElement('video').canPlayType;\r\n}\r\n\r\nfunction supports_h264_baseline_video() {\r\n  if (!supports_video()) { return false; }\r\n  var v = document.createElement(\"video\");\r\n  return v.canPlayType('video/mp4; codecs=\"avc1.42E01E, mp4a.40.2\"');\r\n}\r\n\r\nfunction supports_ogg_theora_video() {\r\n  if (!supports_video()) { return false; }\r\n  var v = document.createElement(\"video\");\r\n  return v.canPlayType('video/ogg; codecs=\"theora, vorbis\"');\r\n}\r\n\r\nfunction supports_webm_video() {\r\n  if (!supports_video()) { return false; }\r\n  var v = document.createElement(\"video\");\r\n  return v.canPlayType('video/webm; codecs=\"vp8, vorbis\"');\r\n}"]],"start1":0,"start2":0,"length1":0,"length2":13493}]],"length":13493,"saved":false}
{"contributors":[],"silentsave":false,"ts":1354047913588,"patch":[[{"diffs":[[0," playing\r\n\t\t"],[1,"/*"],[0,"video.addEve"]],"start1":4858,"start2":4858,"length1":24,"length2":26},{"diffs":[[0,"\t\t}, false);"],[1,"*/"],[0,"\r\n\t\t\r\n\t\t// c"]],"start1":5025,"start2":5025,"length1":24,"length2":26}]],"length":13497,"saved":false}
{"contributors":[],"silentsave":false,"ts":1354048789459,"patch":[[{"diffs":[[0,"ying\r\n\t\t"],[-1,"/*"],[0,"video.ad"]],"start1":4862,"start2":4862,"length1":18,"length2":16},{"diffs":[[0," false);"],[-1,"*/"],[0,"\r\n\t\t\r\n\t\t"]],"start1":5027,"start2":5027,"length1":18,"length2":16}]],"length":13493,"saved":false}
{"ts":1354049003623,"patch":[[{"diffs":[[0," playing\r\n\t\t"],[1,"/*"],[0,"video.addEve"]],"start1":4858,"start2":4858,"length1":24,"length2":26},{"diffs":[[0,"\t\t}, false);"],[1,"*/"],[0,"\r\n\t\t\r\n\t\t// c"]],"start1":5025,"start2":5025,"length1":24,"length2":26}]],"length":13497,"saved":false}
{"ts":1354049808922,"patch":[[{"diffs":[[0,"ying\r\n\t\t"],[-1,"/*"],[0,"video.ad"]],"start1":4862,"start2":4862,"length1":18,"length2":16},{"diffs":[[0," false);"],[-1,"*/"],[0,"\r\n\t\t\r\n\t\t"]],"start1":5027,"start2":5027,"length1":18,"length2":16}]],"length":13493,"saved":false}
